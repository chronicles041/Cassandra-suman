{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c87b9c1a",
   "metadata": {},
   "source": [
    "# IMDB Movie Review Sentiment Analysis - Suman Malla - 200537767\n",
    "\n",
    "##### In this project, we will analyze a dataset of IMDB movie reviews, preprocess the text data, and classify the reviews as positive or negative. The analysis will include text preprocessing, feature extraction using TFIDF, and model training using Random Forest and Gradient Boosting/XGBoost classifiers. We will also explore parameter tuning using GridSearchCV to optimize the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a360594",
   "metadata": {},
   "source": [
    "## Installing necessary packages  at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c06e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in /home/suman/anaconda3/lib/python3.10/site-packages (2024.8.0)\n",
      "Requirement already satisfied: dask-ml in /home/suman/anaconda3/lib/python3.10/site-packages (2024.4.4)\n",
      "Requirement already satisfied: pandas in /home/suman/anaconda3/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /home/suman/anaconda3/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: nltk in /home/suman/anaconda3/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask) (6.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask) (2022.11.0)\n",
      "Requirement already satisfied: click>=8.1 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/suman/.local/lib/python3.10/site-packages (from dask) (21.3)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask) (8.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask) (2.0.0)\n",
      "Requirement already satisfied: multipledispatch>=0.4.9 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask-ml) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/suman/.local/lib/python3.10/site-packages (from dask-ml) (1.23.2)\n",
      "Requirement already satisfied: dask-glm>=0.2.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask-ml) (0.3.2)\n",
      "Requirement already satisfied: distributed>=2.4.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask-ml) (2024.8.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask-ml) (0.56.4)\n",
      "Requirement already satisfied: scipy in /home/suman/anaconda3/lib/python3.10/site-packages (from dask-ml) (1.10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/suman/anaconda3/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/suman/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/suman/anaconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/suman/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: tqdm in /home/suman/anaconda3/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/suman/anaconda3/lib/python3.10/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: sparse>=0.7.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask-glm>=0.2.0->dask-ml) (0.15.4)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask) (1.1.10)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /home/suman/anaconda3/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (1.26.14)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /home/suman/.local/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (3.1.2)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /home/suman/anaconda3/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (6.1)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /home/suman/.local/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (5.9.1)\n",
      "Requirement already satisfied: locket>=1.0.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (1.0.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /home/suman/anaconda3/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (2.4.0)\n",
      "Requirement already satisfied: zict>=3.0.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from distributed>=2.4.0->dask-ml) (3.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/suman/anaconda3/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask) (3.11.0)\n",
      "Requirement already satisfied: six in /home/suman/anaconda3/lib/python3.10/site-packages (from multipledispatch>=0.4.9->dask-ml) (1.16.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/suman/anaconda3/lib/python3.10/site-packages (from numba>=0.51.0->dask-ml) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /home/suman/anaconda3/lib/python3.10/site-packages (from numba>=0.51.0->dask-ml) (65.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/suman/anaconda3/lib/python3.10/site-packages (from packaging>=20.0->dask) (3.0.9)\n",
      "Requirement already satisfied: pyarrow>=7.0.0 in /home/suman/anaconda3/lib/python3.10/site-packages (from dask-expr<1.2,>=1.1->dask) (17.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/suman/.local/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed>=2.4.0->dask-ml) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install dask dask-ml pandas scikit-learn nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a738f",
   "metadata": {},
   "source": [
    "## Importing all the necessary library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162f2fb",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abcc3a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This movie made it into one of my top 10 most ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I had the terrible misfortune of having to vie...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What an absolutely stunning movie, if you have...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>This was the worst movie I saw at WorldFest an...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Karen Carpenter Story shows a little more ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This film tried to be too many things all at o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   I thought this was a wonderful way to spend ti...  positive\n",
       "1   Probably my all-time favorite movie, a story o...  positive\n",
       "2   I sure would like to see a resurrection of a u...  positive\n",
       "3   This show was an amazing, fresh & innovative i...  negative\n",
       "4   Encouraged by the positive comments about this...  negative\n",
       "5   Phil the Alien is one of those quirky films wh...  negative\n",
       "6   I saw this movie when I was about 12 when it c...  negative\n",
       "7   So im not a big fan of Boll's work but then ag...  negative\n",
       "8   This a fantastic movie of three prisoners who ...  positive\n",
       "9   This movie made it into one of my top 10 most ...  negative\n",
       "10  I had the terrible misfortune of having to vie...  negative\n",
       "11  What an absolutely stunning movie, if you have...  positive\n",
       "12  This was the worst movie I saw at WorldFest an...  negative\n",
       "13  The Karen Carpenter Story shows a little more ...  positive\n",
       "14  This film tried to be too many things all at o...  negative"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# Load the IMDB dataset using Dask\n",
    "ddf = dd.read_csv('IMDB_dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "ddf.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ff236",
   "metadata": {},
   "source": [
    "## 1. Preprocess Text Data (3 pts):\n",
    "- ***Remove Punctuation: Strip punctuation marks to clean the text.***\n",
    "- ***Tokenization: Break down the text into individual words or tokens.***\n",
    "- ***Remove Stopwords: Eliminate common words that do not contribute much to the sentiment (e.g., \"the,\" \"is,\" \"and\").***\n",
    "- ***Lemmatization/Stemming: Reduce words to their base or root form (e.g., \"running\" to \"run\").***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba36aaf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/suman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/suman/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/suman/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>probably alltime favorite movie story selfless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like see resurrection dated seahunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>show amazing fresh innovative idea 70 first ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>encouraged positive comment film looking forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>phil alien one quirky film humour based around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>saw movie 12 came recall scariest scene big bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>im big fan boll work many enjoyed movie postal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>fantastic movie three prisoner become famous o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This movie made it into one of my top 10 most ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>movie made one top 10 awful movie horrible was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I thought this was a wonderful way to spend ti...  positive   \n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  Encouraged by the positive comments about this...  negative   \n",
       "5  Phil the Alien is one of those quirky films wh...  negative   \n",
       "6  I saw this movie when I was about 12 when it c...  negative   \n",
       "7  So im not a big fan of Boll's work but then ag...  negative   \n",
       "8  This a fantastic movie of three prisoners who ...  positive   \n",
       "9  This movie made it into one of my top 10 most ...  negative   \n",
       "\n",
       "                                    processed_review  \n",
       "0  thought wonderful way spend time hot summer we...  \n",
       "1  probably alltime favorite movie story selfless...  \n",
       "2  sure would like see resurrection dated seahunt...  \n",
       "3  show amazing fresh innovative idea 70 first ai...  \n",
       "4  encouraged positive comment film looking forwa...  \n",
       "5  phil alien one quirky film humour based around...  \n",
       "6  saw movie 12 came recall scariest scene big bi...  \n",
       "7  im big fan boll work many enjoyed movie postal...  \n",
       "8  fantastic movie three prisoner become famous o...  \n",
       "9  movie made one top 10 awful movie horrible was...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize the necessary tools for text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = text.replace('<br />', ' ')\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
    "    \n",
    "    # Tokenization and remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply text preprocessing in parallel using Dask\n",
    "ddf['processed_review'] = ddf['review'].map(preprocess_text, meta=('review', 'str'))\n",
    "\n",
    "ddf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc71f5",
   "metadata": {},
   "source": [
    "## 2.TF-IDF Vectorization (2 pts):\n",
    "Converting the preprocessed text into numerical features using the TF-IDF (Term Frequency-Inverse Document Frequency) technique. This will help to weigh the importance of each word in a review relative to the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd064979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the processed Dask DataFrame to a Pandas DataFrame\n",
    "df = ddf.compute()\n",
    "\n",
    "# Define the target variable\n",
    "y = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# TFIDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['processed_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00c8afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e55c63b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/suman/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/suman/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/suman/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/suman/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/suman/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/suman/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/suman/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'max_depth': 20, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_params = {'n_estimators': [100, 200], 'max_depth': [10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=3, n_jobs=-1, verbose=1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Parameters for Random Forest: {rf_grid.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4c6b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best Parameters for Gradient Boosting: {'learning_rate': 0.1, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Hyperparameter tuning for Gradient Boosting\n",
    "gb_params = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
    "gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_params, cv=3, n_jobs=-1, verbose=1)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Parameters for Gradient Boosting: {gb_grid.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d388ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8438\n",
      "Random Forest Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      2527\n",
      "           1       0.82      0.88      0.85      2473\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.85      0.84      0.84      5000\n",
      "weighted avg       0.85      0.84      0.84      5000\n",
      "\n",
      "Gradient Boosting Accuracy: 0.8336\n",
      "Gradient Boosting Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      2527\n",
      "           1       0.80      0.88      0.84      2473\n",
      "\n",
      "    accuracy                           0.83      5000\n",
      "   macro avg       0.84      0.83      0.83      5000\n",
      "weighted avg       0.84      0.83      0.83      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_pred = rf_best.predict(X_test)\n",
    "print(f'Random Forest Accuracy: {accuracy_score(y_test, rf_pred)}')\n",
    "print(\"Random Forest Classification Report\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Evaluate Gradient Boosting\n",
    "gb_best = gb_grid.best_estimator_\n",
    "gb_pred = gb_best.predict(X_test)\n",
    "print(f'Gradient Boosting Accuracy: {accuracy_score(y_test, gb_pred)}')\n",
    "print(\"Gradient Boosting Classification Report\")\n",
    "print(classification_report(y_test, gb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9f79c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
